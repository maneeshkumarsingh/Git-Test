import streamlit as stimport seaborn as snsimport pandas as pdimport reimport picklefrom nltk.corpus import stopwordsimport numpy as npimport jsonimport loggingpd.options.mode.chained_assignment = Nonefrom sklearn.ensemble import RandomForestClassifierfrom sklearn.metrics import accuracy_scoreimport base64import timetimestr = time.strftime("%Y%m%d-%H%M%S")from sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import confusion_matrixfrom sklearn.metrics import precision_recall_fscore_support, classification_report,confusion_matrix, precision_recall_curveimport matplotlib.pyplot as pltwith open('Spam_Ham_Config.json') as config_file:  config = json.load(config_file)TrainingData_path = config["TRAINING_DATA_PATH"]Log_path = config['LOG_PATH']vectorizer_filename = config['TEST_VECTORIZER']model_filename = config['TEST_MODEL']nltk_path = config['NLTK_PATH']logging.basicConfig(filename=Log_path, level=logging.INFO, format='%(asctime)s|%(levelname)s:%(lineno)d]%(message)s')def text_process(mess):    try:        assert(type(mess) == str)        cleaned = re.sub(r'\b[\w\-.]+?@\w+?\.\w{2,4}\b', 'emailaddr', mess)        cleaned = re.sub(r'(http[s]?\S+)|(\w+\.[A-Za-z]{2,4}\S*)', 'httpaddr', cleaned)        cleaned = re.sub(r'\b(\+\d{1,2}\s)?\d?[\-(.]?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4}\b','phonenumbr', cleaned)        cleaned = re.sub(r'[^\w\d\s]', ' ', cleaned)        cleaned = re.sub(r'\s+', ' ', cleaned)        cleaned = re.sub(r'^\s+|\s+?$', '', cleaned.lower())        nopunc=''.join(cleaned)        return ' '.join(word.lower() for word in nopunc.split() if word not in stopwords.words('english') if len(word) != 1)    except Exception as e:        print("Exception in loading Text Process", e)        logging.error(f'Exception in loading Text Process:{e}')def plot_confusion_matrix(test_y, predict_y):    C = confusion_matrix(test_y, predict_y)    A = (((C.T) / (C.sum(axis=1))).T)    B = (C / C.sum(axis=0))    fig, ax = plt.subplots(figsize=(20, 4))    #plt.figure(figsize=(20, 4))    labels = [1, 2]    # representing A in heatmap format    cmap = sns.light_palette("blue")    plt.subplot(1, 3, 1)    sns.heatmap(C, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)    plt.xlabel('Predicted Class')    plt.ylabel('Original Class')    plt.title("Confusion matrix")    plt.subplot(1, 3, 2)    sns.heatmap(B, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)    plt.xlabel('Predicted Class')    plt.ylabel('Original Class')    plt.title("Precision matrix")    plt.subplot(1, 3, 3)    # representing B in heatmap format    sns.heatmap(A, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)    plt.xlabel('Predicted Class')    plt.ylabel('Original Class')    plt.title("Recall matrix")    st.pyplot(fig)def train(training_df):    #global training_df    try:        vectorizer = TfidfVectorizer()  # max_features=2500, min_df=7, max_df=0.8)        X_ngrams = vectorizer.fit_transform(training_df['training_messages'])        #################################################        x_train, x_test, y_train, y_test = train_test_split(X_ngrams, training_df['Labels'], shuffle=True, test_size=0.2,                                                            random_state=42)  # , stratify=training_df['labels'])        # spam_detect_model = RandomForestClassifier(n_estimators=100).fit(X_ngrams, training_df['labels'])        st.write('Model Training Start')        ml_model = RandomForestClassifier(n_estimators=250, random_state=0)        ml_model.fit(x_train, y_train)        st.write("ML Model is Trained successfully :smiley:")        # Save the vectorizer        # pickle.dump(vectorizer, open(vectorizer_save, 'wb'))        pickle.dump(vectorizer, open(vectorizer_filename, 'wb'))        # Saving Model        # pickle.dump(A2P_P2P_detect_model, open(model_save, 'wb'))        pickle.dump(ml_model, open(model_filename, 'wb'))        st.write("ML Model successfully save in pickle :smiley:")        preds = ml_model.predict(x_test)        accuracy = accuracy_score(preds, y_test)        st.write('accuracy = ', accuracy)        st.write(plot_confusion_matrix(y_test, preds))        # st.metric(classification_report(y_test, preds))        st.text('Model Report:\n ' + classification_report(y_test, preds))        logging.critical('ML Model is Trained successfully ')    except Exception as exception:            print("Exception in training model", exception)            logging.info(f'Exception in training model:{exception}')if __name__ == '__main__':    train()